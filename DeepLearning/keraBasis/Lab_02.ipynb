{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHI8oLVYcolR"
      },
      "source": [
        "# Lab 2 - introducing Practical Modelling in Keras\n",
        "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/andrew-nash/CS6421-labs-2025/blob/main/CS6421_Lab_02.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {
        "id": "MjbPNQP8ddI6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10emXPO_UbPR"
      },
      "source": [
        "## Tensors (https://www.tensorflow.org/guide/basics)\n",
        "\n",
        "The basic data structure in TensorFlow is the tf.Tensor, which is very similar to the np.array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = tf.constant([\n",
        "    [1., 2., 3.],\n",
        "    [4., 5., 6.]\n",
        "    ])\n",
        "\n",
        "vx = tf.Variable([\n",
        "    [1., 2., 3.],\n",
        "    [4., 5., 6.]\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "execution_count": 326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "execution_count": 327,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhlSQUzDVEhJ"
      },
      "source": [
        "## Mathematical operations\n",
        "\n",
        "These can be performed in much the same way as NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "P5omQ5GQVBmO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=6.5>"
            ]
          },
          "execution_count": 328,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.constant(3.25, dtype=tf.float32)\n",
        "x \n",
        "x * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "execution_count": 329,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[  2.7182817,   7.389056 ,  20.085537 ],\n",
              "       [ 54.59815  , 148.41316  , 403.4288   ]], dtype=float32)>"
            ]
          },
          "execution_count": 330,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(vx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
              "array([[ 38,  44,  50,  56],\n",
              "       [ 83,  98, 113, 128]], dtype=int32)>"
            ]
          },
          "execution_count": 331,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = tf.constant([[1,2,3],[4,5,6]])\n",
        "B = tf.constant([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
        "\n",
        "C = tf.matmul(A, B)\n",
        "C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([2, 4])"
            ]
          },
          "execution_count": 332,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwuTvmnR5QWN"
      },
      "source": [
        "## Auto-differentiation\n",
        "\n",
        "One of the most imporant differces over NumPy is TensorFlow's ability to autmatically differentiate user-defined functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "id": "Q1j8FYU85SEL"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    return x**2 + 2*x - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "FgK9h_0y5TLL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
            ]
          },
          "execution_count": 334,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.Variable(2.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = f(x)\n",
        "  \n",
        "g_x = tape.gradient(y, x)\n",
        "g_x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emvzZ8Ew5U8K"
      },
      "source": [
        "This also works over multi-variate functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "gY9_WXVc5W65"
      },
      "outputs": [],
      "source": [
        "def f2(x):\n",
        "    # y = 5*x + 2*exp(x)\n",
        "    return tf.add(tf.multiply(x, tf.constant(5.0)), tf.multiply(tf.constant(2.0), tf.exp(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "fx7f5UJ85ZIO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
              "array([ 10.4365635,  19.778112 ,  45.171074 , 114.1963   , 301.82632  ],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 336,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = tf.Variable([1.0,2.0,3.0,4.0,5.0])\n",
        "with tf.GradientTape() as tape:\n",
        "    y = f2(x)\n",
        "\n",
        "g_x = tape.gradient(y, x)\n",
        "g_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIYToNdU5acr"
      },
      "source": [
        "These are the tools that will allow us to implement our own layers, activation functions and loss functions to add to Keras models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcE3zaaZ5F8o"
      },
      "source": [
        "# Data Loading And Cleaning\n",
        "\n",
        "For this lab, we will use a pre-loaded dataset from TensorFlow - the MNIST (Modified NIST) dataset. This is a set of 70,000 28x28 greyscale images, with associated labels, of handwritten digits (0-9).\n",
        "\n",
        "In this case TensorFlow has already split up the dataset to give us 60k images for training, and a separate 10k for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "id": "Mjoxz44ScZ4v"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O2DpnDQeGSu"
      },
      "source": [
        "**QUESTION** - why bother dividing the data by 255?\n",
        "\n",
        "We will revisit this later in the lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "id": "sx3TrRA6dfdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape (60000, 28, 28)\n",
            "Test shape (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train shape\", x_train.shape)\n",
        "print(\"Test shape\",  x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "id": "GePMzVY2dhXk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1581653d0>"
            ]
          },
          "execution_count": 339,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "id": "pUlvrNWipRJI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x158507d10>"
            ]
          },
          "execution_count": 340,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(x_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwCJZ8S0go6R"
      },
      "source": [
        "**EXERCISE**: Currently, `x_train` and `x_test` are arrays of square 28x28 images. For today, we are not going to be working with image-specific architectures and instead will pass our inputs as 784-length vectors instead of 28x28 images.\n",
        "\n",
        "Use NumPy to transform `x_train` and `x_test` accordingly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 341,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "id": "cAflGgQvgwSv"
      },
      "outputs": [],
      "source": [
        "x_train_clean = np.reshape(x_train, (x_train.shape[0], 784))\n",
        "x_test_clean = np.reshape(x_test, (x_test.shape[0], 784))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FDsBHBMiy8Y"
      },
      "source": [
        "Now lets consider our output labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "id": "0S_rGjstiiBW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000,), (10000,))"
            ]
          },
          "execution_count": 343,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "id": "O5zX-AZDjIPU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "execution_count": 344,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SzmYNEZi4Nr"
      },
      "source": [
        "`y_train` and `y_test` are simply arrays of numeric labels from 0-9.\n",
        "\n",
        "Is this categorical, or quantitative data? Is there an inherent ordering to the values?\n",
        "\n",
        "Therefore, is this the best possible data encoding for us to directly predict?\n",
        "\n",
        "### One-hot Encoding\n",
        "\n",
        "This is a more computer-friendly way of encoding categorical data.\n",
        "\n",
        "The idea is, if there are $K$ possible values of our data, we represent each value as a vector of length $K$. One value of this vector is 1, while the rest remain 0.\n",
        "\n",
        "E.g., if we want to encode a persons blood group (which is one of AB+, AB-, A+, A-, B+, B-, O+, O-) we could do the following:\n",
        "\n",
        "Type | Encoded Vector |\n",
        "---- | ----  |\n",
        "AB+ | [1,0,0,0,0,0,0,0]\n",
        "AB- | [0,1,0,0,0,0,0,0]\n",
        "A+ | [0,0,1,0,0,0,0,0]\n",
        "A- | [0,0,0,1,0,0,0,0]\n",
        "B+ | [0,0,0,0,1,0,0,0]\n",
        "B- | [0,0,0,0,0,1,0,0]\n",
        "O+ | [0,0,0,0,0,0,1,0]\n",
        "O- | [0,0,0,0,0,0,0,1]\n",
        "\n",
        "The code to perform this transformation in tensorflow is simple.\n",
        "\n",
        "In our case, because our data consists of the numbers 0-9, we can let our raw labels be the indices of the '1' value in the one-hot encoding.\n",
        "\n",
        "I.e.\n",
        "\n",
        "Type | Encoded Vector |\n",
        "---- | ----  |\n",
        "0 | [1,0,0,0,0,0,0,0,0,0]\n",
        "1 | [0,1,0,0,0,0,0,0,0,0]\n",
        "2 | [0,0,1,0,0,0,0,0,0,0]\n",
        "3 | [0,0,0,1,0,0,0,0,0,0]\n",
        "4 | [0,0,0,0,1,0,0,0,0,0]\n",
        "5 | [0,0,0,0,0,1,0,0,0,0]\n",
        "6 | [0,0,0,0,0,0,1,0,0,0]\n",
        "7 | [0,0,0,0,0,0,0,1,0,0]\n",
        "8 | [0,0,0,0,0,0,0,0,1,0]\n",
        "9 | [0,0,0,0,0,0,0,0,0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "id": "MBytsRXsi3pz"
      },
      "outputs": [],
      "source": [
        "y_train_clean = tf.one_hot(indices=y_train, depth=10)\n",
        "y_test_clean = tf.one_hot(indices=y_test, depth=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZqJBH2qmfm7"
      },
      "source": [
        "It is important to note that if your labels do not consist of the integers $0,1,2,3,4,\\dots$ additional processing will be required to produce the one-hot vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvlsNRMbefiB"
      },
      "source": [
        "## Model Design Process\n",
        "\n",
        "We will now step through the process described to you in the lectures so far\n",
        "\n",
        "1. Define Model\n",
        "2. Compile Model\n",
        "3. Train Model\n",
        "4. Save Model (optional)\n",
        "5. Save Best Weights (optional)\n",
        "6. Evaluate Model\n",
        "7. Predict using saved Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbbzctRse_ZP"
      },
      "source": [
        "### Define Model\n",
        "\n",
        "In Keras, there are two main methods of defining a model - the Sequential API or the Functional API.\n",
        "\n",
        "The Functional API has greater capability, at the price of extra code complexity. For now, we will focus on the Sequential API and introduce the functional API only once we introduce more complex models.\n",
        "\n",
        "Sequential models are defined in a striaightforward layer-by-layer basis.\n",
        "\n",
        "It is possible to implement your own type of layer, or use a pre-defined one from Keras' comprehensive list at https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
        "\n",
        "It is critical to define the input and output shapes correctly - in this case our inputs are 784 length vectors, and our ouputs are vectors of length 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "FUW3NNYle9UX"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(784,)))\n",
        "model.add(tf.keras.layers.Dense(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY4sC43ViHu3"
      },
      "source": [
        "**Pay attention** to the trailing comma after 784 - this is needed when our shape is a single value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "aeNw_zuGh6xJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m7,850\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yFUu8MiUyO"
      },
      "source": [
        "This is the simplest possible model - with no activation function, and just one weight matrix and bias vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cLnWyNrfCyF"
      },
      "source": [
        "### Compile Model\n",
        "\n",
        "This is where we specify our training hyper-parameters.\n",
        "\n",
        "If you wish, you can define your own functions using tensorflow operations for any of these. Keras includes a library of loss functons, metrics and optimizers at:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "id": "QhDuiaPcfE17"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer= \"SGD\",\n",
        "    loss = \"mean_squared_error\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFV-3PnGfFHQ"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "IFPkonuGoFiE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "EakUoDrufHIn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.2709 - loss: 0.1545 - val_accuracy: 0.5645 - val_loss: 0.0878\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.5817 - loss: 0.0844 - val_accuracy: 0.6672 - val_loss: 0.0723\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.6696 - loss: 0.0716 - val_accuracy: 0.7180 - val_loss: 0.0649\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7196 - loss: 0.0648 - val_accuracy: 0.7472 - val_loss: 0.0604\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.7454 - loss: 0.0608 - val_accuracy: 0.7676 - val_loss: 0.0574\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x14fdd4b60>"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    x_train_clean,\n",
        "    y_train_clean,\n",
        "    epochs=5,\n",
        "    batch_size = 128,\n",
        "    validation_data = (x_test_clean,y_test_clean)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocMWrz4qfHQR"
      },
      "source": [
        "### Save Model\n",
        "\n",
        "It is critically important to pick meaninful, and unique names for each model you train - and keep track of what saved model corresponsed to what training run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "U0UU6QNefJfH"
      },
      "outputs": [],
      "source": [
        "model.save(\"simple_model_def_op_no_act.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKpKCNiWfK7D"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "id": "DbejbSVzfKTD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7325 - loss: 0.0606\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.057370591908693314, 0.7675999999046326]"
            ]
          },
          "execution_count": 321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(\"simple_model_def_op_no_act.keras\")\n",
        "model.evaluate(x_test_clean, y_test_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VJWzMhmfM16"
      },
      "source": [
        "### Predict Using Saved Model\n",
        "\n",
        "**EXERCISE** Get the first image out of x_test_clean. Make sure its shape is (1,784) and not just (784)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {
        "id": "zlV11ut6fSNn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              "array([[ 0.09092485,  0.0212313 ,  0.06347112, -0.02390962, -0.03296297,\n",
              "        -0.07960513,  0.03362428,  0.693487  , -0.07357356,  0.00824115]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 346,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datapoint = x_test_clean[0].reshape(1, 784)\n",
        "model(datapoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV2WMu8NfTAE"
      },
      "source": [
        "## Model Architecture Improvements\n",
        "\n",
        "Clearly, this simple model could use some improvement.\n",
        "\n",
        "We can add:\n",
        "\n",
        "1. Additional layers\n",
        "2. Activation Functions\n",
        "3. Regularization (Dropout and BatchNorm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "id": "KpbxCi9VfZN4"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(784,)))\n",
        "model.add(tf.keras.layers.Dense(128, activation=\"sigmoid\"))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "id": "ptw7oclU9h-y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,282</span> (399.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,282\u001b[0m (399.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,026</span> (398.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m102,026\u001b[0m (398.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcoivK129l7E"
      },
      "source": [
        "We can also choose a more appropiate optimizer and loss function for this particular case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "9LqE_pM59siQ"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer= \"Adam\",\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "id": "KxsjmSMq9zJx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.8392 - val_accuracy: 0.9255 - val_loss: 0.2625\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2909 - val_accuracy: 0.9463 - val_loss: 0.1833\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.2190 - val_accuracy: 0.9572 - val_loss: 0.1463\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.1780 - val_accuracy: 0.9630 - val_loss: 0.1247\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1461 - val_accuracy: 0.9679 - val_loss: 0.1114\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1585f7bc0>"
            ]
          },
          "execution_count": 351,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    x_train_clean,\n",
        "    y_train_clean,\n",
        "    epochs=5,\n",
        "    batch_size = 128,\n",
        "    validation_data = (x_test_clean,y_test_clean)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"simple_model_def_op_no_act.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrQQ_2kq-4vJ"
      },
      "source": [
        "# Hyper-parameter Optimzation\n",
        "\n",
        "For simplicity, we will use the Keras tuner to partially automate this process (https://www.tensorflow.org/tutorials/keras/keras_tuner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7XTo6opAOy9"
      },
      "source": [
        "## Model Builder Function\n",
        "\n",
        "The first step is to define a function over the hyper-parameters of interest, that returns the validation metrics.\n",
        "\n",
        "We will then search over these arguments to find their optimal values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDmFSeI3Cqi5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyo0RYS8H7nn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG4ghsYRCnRE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7797hI-Cc2R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFWfnKKsBcKT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VosAlmeDFKCB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPip9VYMFXQ-"
      },
      "source": [
        "It is good practice when tuning these hyper-parameters to not use the test dataset for tuning - we will perform a separate split on our training data, and evaluate on thetest dataset post-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy909s8eRZMD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS9fg3ozE1rw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCt0-UyBTETP"
      },
      "source": [
        "**IMPORTANT** If you are using Google colab, the results will not be saved, once your notebook times out everything will be discarded.\n",
        "\n",
        "Download any files or details you don't want to lose immediately.\n",
        "\n",
        "Below are the highest scoring hyper-parameters. Be sure to closely examine the TensorBoard metrics for a better understanding of performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv3U-IU1Sgxy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJO5tguNS0r-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHs0ZExxS8QW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQyzS7hjF-PO"
      },
      "source": [
        "# Optional (But Recommended) Practice - Not Graded\n",
        "\n",
        "This practice is not graded, but praciticing this task will prove useful for completing assignment 1.\n",
        "\n",
        "Using keras_tuner (the various methods like hp.Int() and hp.Choice() are documented at https://keras.io/keras_tuner/api/hyperparameters/), try optimize the different hyper-parameters above model architecture.\n",
        "\n",
        "You do not have to perform all of the optimization in one single search.\n",
        "\n",
        "Refer to Lecture L06 as a guide for what to target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZDBajuTF9le"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
