{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2 - introducing Practical Modelling in Keras\n",
        "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/andrew-nash/CS6421-labs-2025/blob/main/CS6421_Lab_02.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "GHI8oLVYcolR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "MjbPNQP8ddI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors (https://www.tensorflow.org/guide/basics)\n",
        "\n",
        "The basic data structure in TensorFlow is the tf.Tensor, which is very similar to the np.array"
      ],
      "metadata": {
        "id": "10emXPO_UbPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An immutable Tensor\n",
        "x = tf.constant([[1., 2., 3.],\n",
        "                 [4., 5., 6.]])\n",
        "# A mutable Tensor\n",
        "vx = tf.Variable([[1., 2., 3.],\n",
        "                 [4., 5., 6.]])\n"
      ],
      "metadata": {
        "id": "UqtMhQxcUoZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "2x_pN-LEUpPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vx"
      ],
      "metadata": {
        "id": "thnzcuJLVBM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mathematical operations\n",
        "\n",
        "These can be performed in much the same way as NumPy"
      ],
      "metadata": {
        "id": "WhlSQUzDVEhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(1.75, dtype=tf.float32)\n",
        "x\n",
        "x*2"
      ],
      "metadata": {
        "id": "P5omQ5GQVBmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(x)"
      ],
      "metadata": {
        "id": "japrw1boVTiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = tf.constant([[1,2,3],[4,5,6]])\n",
        "B = tf.constant([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
        "\n",
        "C=tf.matmul(A,B)\n",
        "C"
      ],
      "metadata": {
        "id": "GJlnOi1nXN5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape"
      ],
      "metadata": {
        "id": "HV3ZL3cZXeTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto-differentiation\n",
        "\n",
        "One of the most imporant differces over NumPy is TensorFlow's ability to autmatically differentiate user-defined functions"
      ],
      "metadata": {
        "id": "CwuTvmnR5QWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  y = x**2 + 2*x - 5\n",
        "  return y"
      ],
      "metadata": {
        "id": "Q1j8FYU85SEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(2.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = f(x)\n",
        "\n",
        "g_x = tape.gradient(y, x)\n",
        "g_x"
      ],
      "metadata": {
        "id": "FgK9h_0y5TLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This also works over multi-variate functions"
      ],
      "metadata": {
        "id": "emvzZ8Ew5U8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f2(x):\n",
        "  # y = 5*x + 2*exp(x)\n",
        "  A = tf.constant(5.0)\n",
        "  B = tf.constant(2.0)\n",
        "  y = tf.add(tf.multiply(x,A), tf.multiply(B, tf.exp(x)))\n",
        "  return y"
      ],
      "metadata": {
        "id": "gY9_WXVc5W65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable([1.0,2.0,3.0,4.0,5.0])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = f2(x)\n",
        "\n",
        "g_x = tape.gradient(y, x)\n",
        "g_x"
      ],
      "metadata": {
        "id": "fx7f5UJ85ZIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the tools that will allow us to implement our own layers, activation functions and loss functions to add to Keras models."
      ],
      "metadata": {
        "id": "pIYToNdU5acr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading And Cleaning\n",
        "\n",
        "For this lab, we will use a pre-loaded dataset from TensorFlow - the MNIST (Modified NIST) dataset. This is a set of 70,000 28x28 greyscale images, with associated labels, of handwritten digits (0-9).\n",
        "\n",
        "In this case TensorFlow has already split up the dataset to give us 60k images for training, and a separate 10k for evaluation."
      ],
      "metadata": {
        "id": "gcE3zaaZ5F8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjoxz44ScZ4v"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# data normalizing\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION** - why bother dividing the data by 255?\n",
        "\n",
        "We will revisit this later in the lab."
      ],
      "metadata": {
        "id": "4O2DpnDQeGSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape\", x_train.shape)\n",
        "print(\"Test shape\",  x_test.shape)"
      ],
      "metadata": {
        "id": "sx3TrRA6dfdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[0])\n"
      ],
      "metadata": {
        "id": "GePMzVY2dhXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[0])\n"
      ],
      "metadata": {
        "id": "pUlvrNWipRJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXERCISE**: Currently, `x_train` and `x_test` are arrays of square 28x28 images. For today, we are not going to be working with image-specific architectures and instead will pass our inputs as 784-length vectors instead of 28x28 images.\n",
        "\n",
        "Use NumPy to transform `x_train` and `x_test` accordingly\n"
      ],
      "metadata": {
        "id": "fwCJZ8S0go6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_clean = None\n",
        "x_test_clean = None"
      ],
      "metadata": {
        "id": "cAflGgQvgwSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets consider our output labels."
      ],
      "metadata": {
        "id": "5FDsBHBMiy8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "0S_rGjstiiBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "O5zX-AZDjIPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`y_train` and `y_test` are simply arrays of numeric labels from 0-9.\n",
        "\n",
        "Is this categorical, or quantitative data? Is there an inherent ordering to the values?\n",
        "\n",
        "Therefore, is this the best possible data encoding for us to directly predict?\n",
        "\n",
        "### One-hot Encoding\n",
        "\n",
        "This is a more computer-friendly way of encoding categorical data.\n",
        "\n",
        "The idea is, if there are $K$ possible values of our data, we represent each value as a vector of length $K$. One value of this vector is 1, while the rest remain 0.\n",
        "\n",
        "E.g., if we want to encode a persons blood group (which is one of AB+, AB-, A+, A-, B+, B-, O+, O-) we could do the following:\n",
        "\n",
        "Type | Encoded Vector |\n",
        "---- | ----  |\n",
        "AB+ | [1,0,0,0,0,0,0,0]\n",
        "AB- | [0,1,0,0,0,0,0,0]\n",
        "A+ | [0,0,1,0,0,0,0,0]\n",
        "A- | [0,0,0,1,0,0,0,0]\n",
        "B+ | [0,0,0,0,1,0,0,0]\n",
        "B- | [0,0,0,0,0,1,0,0]\n",
        "O+ | [0,0,0,0,0,0,1,0]\n",
        "O- | [0,0,0,0,0,0,0,1]\n",
        "\n",
        "The code to perform this transformation in tensorflow is simple.\n",
        "\n",
        "In our case, because our data consists of the numbers 0-9, we can let our raw labels be the indices of the '1' value in the one-hot encoding.\n",
        "\n",
        "I.e.\n",
        "\n",
        "Type | Encoded Vector |\n",
        "---- | ----  |\n",
        "0 | [1,0,0,0,0,0,0,0,0,0]\n",
        "1 | [0,1,0,0,0,0,0,0,0,0]\n",
        "2 | [0,0,1,0,0,0,0,0,0,0]\n",
        "3 | [0,0,0,1,0,0,0,0,0,0]\n",
        "4 | [0,0,0,0,1,0,0,0,0,0]\n",
        "5 | [0,0,0,0,0,1,0,0,0,0]\n",
        "6 | [0,0,0,0,0,0,1,0,0,0]\n",
        "7 | [0,0,0,0,0,0,0,1,0,0]\n",
        "8 | [0,0,0,0,0,0,0,0,1,0]\n",
        "9 | [0,0,0,0,0,0,0,0,0,1]"
      ],
      "metadata": {
        "id": "8SzmYNEZi4Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_clean = tf.one_hot(indices=y_train, depth=10)\n",
        "y_test_clean = tf.one_hot(indices=y_test, depth=10)"
      ],
      "metadata": {
        "id": "MBytsRXsi3pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that if your labels do not consist of the integers $0,1,2,3,4,\\dots$ additional processing will be required to produce the one-hot vectors"
      ],
      "metadata": {
        "id": "UZqJBH2qmfm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Design Process\n",
        "\n",
        "We will now step through the process described to you in the lectures so far\n",
        "\n",
        "1. Define Model\n",
        "2. Compile Model\n",
        "3. Train Model\n",
        "4. Save Model (optional)\n",
        "5. Save Best Weights (optional)\n",
        "6. Evaluate Model\n",
        "7. Predict using saved Model"
      ],
      "metadata": {
        "id": "xvlsNRMbefiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Model\n",
        "\n",
        "In Keras, there are two main methods of defining a model - the Sequential API or the Functional API.\n",
        "\n",
        "The Functional API has greater capability, at the price of extra code complexity. For now, we will focus on the Sequential API and introduce the functional API only once we introduce more complex models.\n",
        "\n",
        "Sequential models are defined in a striaightforward layer-by-layer basis.\n",
        "\n",
        "It is possible to implement your own type of layer, or use a pre-defined one from Keras' comprehensive list at https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
        "\n",
        "It is critical to define the input and output shapes correctly - in this case our inputs are 784 length vectors, and our ouputs are vectors of length 10."
      ],
      "metadata": {
        "id": "UbbzctRse_ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Input(shape=(784,)))\n",
        "model.add(tf.keras.layers.Dense(10))"
      ],
      "metadata": {
        "id": "FUW3NNYle9UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pay attention** to the trailing comma after 784 - this is needed when our shape is a single value"
      ],
      "metadata": {
        "id": "kY4sC43ViHu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "aeNw_zuGh6xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the simplest possible model - with no activation function, and just one weight matrix and bias vector."
      ],
      "metadata": {
        "id": "W7yFUu8MiUyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile Model\n",
        "\n",
        "This is where we specify our training hyper-parameters.\n",
        "\n",
        "If you wish, you can define your own functions using tensorflow operations for any of these. Keras includes a library of loss functons, metrics and optimizers at:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"
      ],
      "metadata": {
        "id": "2cLnWyNrfCyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer= \"SGD\",\n",
        "    loss = \"mean_squared_error\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "QhDuiaPcfE17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "hFV-3PnGfFHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_clean.shape"
      ],
      "metadata": {
        "id": "IFPkonuGoFiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train_clean,\n",
        "    y_train_clean,\n",
        "    epochs=5,\n",
        "    batch_size = 128,\n",
        "    validation_data = (x_test_clean,y_test_clean)\n",
        ")"
      ],
      "metadata": {
        "id": "EakUoDrufHIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model\n",
        "\n",
        "It is critically important to pick meaninful, and unique names for each model you train - and keep track of what saved model corresponsed to what training run."
      ],
      "metadata": {
        "id": "ocMWrz4qfHQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"simple_model_def_op_no_act.keras\")"
      ],
      "metadata": {
        "id": "U0UU6QNefJfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model"
      ],
      "metadata": {
        "id": "VKpKCNiWfK7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"simple_model_def_op_no_act.keras\")\n",
        "model.evaluate(x_test_clean,y_test_clean)"
      ],
      "metadata": {
        "id": "DbejbSVzfKTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Using Saved Model\n",
        "\n",
        "**EXERCISE** Get the first image out of x_test_clean. Make sure its shape is (1,784) and not just (784)."
      ],
      "metadata": {
        "id": "2VJWzMhmfM16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datapoint = x_test_clean[...]\n",
        "model(datapoint)"
      ],
      "metadata": {
        "id": "zlV11ut6fSNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture Improvements\n",
        "\n",
        "Clearly, this simple model could use some improvement.\n",
        "\n",
        "We can add:\n",
        "\n",
        "1. Additional layers\n",
        "2. Activation Functions\n",
        "3. Regularization (Dropout and BatchNorm)\n",
        "\n"
      ],
      "metadata": {
        "id": "QV2WMu8NfTAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Input(shape=(784,)))\n",
        "model.add(tf.keras.layers.Dense(128, activation=\"sigmoid\"))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "KpbxCi9VfZN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "ptw7oclU9h-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also choose a more appropiate optimizer and loss function for this particular case."
      ],
      "metadata": {
        "id": "XcoivK129l7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer= \"Adam\",\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "9LqE_pM59siQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train_clean,\n",
        "    y_train_clean,\n",
        "    epochs=5,\n",
        "    batch_size = 128,\n",
        "    validation_data = (x_test_clean,y_test_clean)\n",
        ")"
      ],
      "metadata": {
        "id": "KxsjmSMq9zJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameter Optimzation\n",
        "\n",
        "For simplicity, we will use the Keras tuner to partially automate this process (https://www.tensorflow.org/tutorials/keras/keras_tuner)"
      ],
      "metadata": {
        "id": "HrQQ_2kq-4vJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Builder Function\n",
        "\n",
        "The first step is to define a function over the hyper-parameters of interest, that returns the validation metrics.\n",
        "\n",
        "We will then search over these arguments to find their optimal values."
      ],
      "metadata": {
        "id": "A7XTo6opAOy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U keras-tuner"
      ],
      "metadata": {
        "id": "PDmFSeI3Cqi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "pyo0RYS8H7nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "zG4ghsYRCnRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_two_layer_model(hp):\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Input(shape=(784,)))\n",
        "\n",
        "  # chosen act function\n",
        "  act = hp.Choice(\"Activation\", [\"relu\", \"sigmoid\"])\n",
        "\n",
        "  # This will test values of the layer size in the range 64-512 on a logarithmic scale\n",
        "  l1_size = hp.Int(\"Layer_1_size\", min_value=64, max_value=512, step=2, sampling='log')\n",
        "  model.add(tf.keras.layers.Dense(l1_size, activation=act))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  # This will test values of the layer size in the range 64-512 on a logarithmic scale\n",
        "  l2_size = hp.Int(\"Layer_2_size\", min_value=64, max_value=512, step=2, sampling='log')\n",
        "  model.add(tf.keras.layers.Dense(l2_size, activation=act))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "K7797hI-Cc2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(build_two_layer_model,\n",
        "                        objective='val_accuracy',\n",
        "                        max_trials=20,\n",
        "                        seed=42,\n",
        "                        overwrite=True,\n",
        "                        directory=\"./hyp_searches/\",\n",
        "                        project_name=\"two_layer_size_search\")"
      ],
      "metadata": {
        "id": "bFWfnKKsBcKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "VosAlmeDFKCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is good practice when tuning these hyper-parameters to not use the test dataset for tuning - we will perform a separate split on our training data, and evaluate on thetest dataset post-optimization"
      ],
      "metadata": {
        "id": "xPip9VYMFXQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir \"./hyp_searches/two_layer_size_search\""
      ],
      "metadata": {
        "id": "oy909s8eRZMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    x_train_clean,\n",
        "    y_train_clean,\n",
        "    validation_split = 0.8,\n",
        "    epochs=5,\n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"./hyp_searches/two_layer_size_search/tb_logs\")]\n",
        ")"
      ],
      "metadata": {
        "id": "OS9fg3ozE1rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT** If you are using Google colab, the results will not be saved, once your notebook times out everything will be discarded.\n",
        "\n",
        "Download any files or details you don't want to lose immediately.\n",
        "\n",
        "Below are the highest scoring hyper-parameters. Be sure to closely examine the TensorBoard metrics for a better understanding of performance."
      ],
      "metadata": {
        "id": "eCt0-UyBTETP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models()[0]"
      ],
      "metadata": {
        "id": "xv3U-IU1Sgxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "id": "iJO5tguNS0r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "id": "CHs0ZExxS8QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional (But Recommended) Practice - Not Graded\n",
        "\n",
        "This practice is not graded, but praciticing this task will prove useful for completing assignment 1.\n",
        "\n",
        "Using keras_tuner (the various methods like hp.Int() and hp.Choice() are documented at https://keras.io/keras_tuner/api/hyperparameters/), try optimize the different hyper-parameters above model architecture.\n",
        "\n",
        "You do not have to perform all of the optimization in one single search.\n",
        "\n",
        "Refer to Lecture L06 as a guide for what to target."
      ],
      "metadata": {
        "id": "CQyzS7hjF-PO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lZDBajuTF9le"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
